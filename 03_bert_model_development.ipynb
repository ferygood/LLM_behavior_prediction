{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferygood/LLM_behavior_prediction/blob/main/03_bert_model_development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vzrWEgkbnDq6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ku4QNCjdnRHi"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>visit_time</th>\n",
              "      <th>page_url</th>\n",
              "      <th>referrer_url</th>\n",
              "      <th>visit_date</th>\n",
              "      <th>visit_hour</th>\n",
              "      <th>purchase_time</th>\n",
              "      <th>product_id</th>\n",
              "      <th>amount</th>\n",
              "      <th>purchase_date</th>\n",
              "      <th>purchase_hour</th>\n",
              "      <th>interaction_time</th>\n",
              "      <th>platform</th>\n",
              "      <th>action</th>\n",
              "      <th>interaction_date</th>\n",
              "      <th>interaction_hour</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>277</td>\n",
              "      <td>2023-01-01 00:00:00</td>\n",
              "      <td>checkout</td>\n",
              "      <td>facebook</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>306</td>\n",
              "      <td>2023-01-01 00:01:00</td>\n",
              "      <td>product</td>\n",
              "      <td>google</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>138</td>\n",
              "      <td>2023-01-01 00:02:00</td>\n",
              "      <td>checkout</td>\n",
              "      <td>twitter</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>998</td>\n",
              "      <td>2023-01-01 00:03:00</td>\n",
              "      <td>home</td>\n",
              "      <td>twitter</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>462</td>\n",
              "      <td>2023-01-01 00:04:00</td>\n",
              "      <td>cart</td>\n",
              "      <td>direct</td>\n",
              "      <td>2023-01-01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id           visit_time  page_url referrer_url  visit_date  \\\n",
              "0      277  2023-01-01 00:00:00  checkout     facebook  2023-01-01   \n",
              "1      306  2023-01-01 00:01:00   product       google  2023-01-01   \n",
              "2      138  2023-01-01 00:02:00  checkout      twitter  2023-01-01   \n",
              "3      998  2023-01-01 00:03:00      home      twitter  2023-01-01   \n",
              "4      462  2023-01-01 00:04:00      cart       direct  2023-01-01   \n",
              "\n",
              "   visit_hour purchase_time  product_id  amount purchase_date  purchase_hour  \\\n",
              "0         0.0           NaN         NaN     NaN           NaN            NaN   \n",
              "1         0.0           NaN         NaN     NaN           NaN            NaN   \n",
              "2         0.0           NaN         NaN     NaN           NaN            NaN   \n",
              "3         0.0           NaN         NaN     NaN           NaN            NaN   \n",
              "4         0.0           NaN         NaN     NaN           NaN            NaN   \n",
              "\n",
              "  interaction_time platform action interaction_date  interaction_hour  \n",
              "0              NaN      NaN    NaN              NaN               NaN  \n",
              "1              NaN      NaN    NaN              NaN               NaN  \n",
              "2              NaN      NaN    NaN              NaN               NaN  \n",
              "3              NaN      NaN    NaN              NaN               NaN  \n",
              "4              NaN      NaN    NaN              NaN               NaN  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load user data\n",
        "web_visit_data = pd.read_csv('data/web_visit_data.csv')\n",
        "purchase_data = pd.read_csv('data/purchase_data.csv')\n",
        "social_interaction_data = pd.read_csv('data/social_interaction_data.csv')\n",
        "\n",
        "# combine data (need to check column and user ID)\n",
        "data = pd.concat([web_visit_data, purchase_data, social_interaction_data], ignore_index=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fmxp9eGjnqs7"
      },
      "outputs": [],
      "source": [
        "# create label feature, our goal is to predict if a user will be a certain product\n",
        "data['label'] = data['amount'].apply(lambda x: 1 if x > 0 else 0)\n",
        "\n",
        "# select related features\n",
        "features = data[['page_url', 'referrer_url', 'platform', 'action']]\n",
        "labels = data['label']\n",
        "\n",
        "# train & test split\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF2eBuXVn7pw"
      },
      "source": [
        "Then we start developing our model and train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UTZnRTY4n6Ri"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yaochung41/Desktop/ferygood_github/LLM_behavior_prediction/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/Users/yaochung41/Desktop/ferygood_github/LLM_behavior_prediction/.venv/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "\n",
        "class UserBehaviorDataset(Dataset):\n",
        "    def __init__(self, features, labels, tokenizer, max_len):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.features.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "\n",
        "        # combine all features as one sentence\n",
        "        text = ' '.join([str(value) for value in feature])\n",
        "\n",
        "        # tokenize\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# model parameters\n",
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 4\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "# load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# 創建數據集和數據加載器\n",
        "train_dataset = UserBehaviorDataset(train_features, train_labels, tokenizer, MAX_LEN)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "test_dataset = UserBehaviorDataset(test_features, test_labels, tokenizer, MAX_LEN)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# 加載BERT模型\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# 設置優化器 AdamW\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# 訓練模型\n",
        "def train_model(model, data_loader, optimizer, device, epochs):\n",
        "    model = model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                labels=labels\n",
        "            )\n",
        "\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        avg_loss = total_loss / len(data_loader)\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "# 訓練模型\n",
        "train_model(model, train_loader, optimizer, 'cuda' if torch.cuda.is_available() else 'cpu', EPOCHS)\n",
        "\n",
        "# 保存模型\n",
        "model.save_pretrained('bert_user_behavior_model')\n",
        "tokenizer.save_pretrained('bert_user_behavior_tokenizer')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqF9x0imofTh"
      },
      "source": [
        "evaluate if the model is good or bad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2y4YOk1eojiS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def evaluate_model(model, data_loader, device):\n",
        "    model = model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in data_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=1)\n",
        "\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    report = classification_report(true_labels, predictions)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# 評估模型\n",
        "accuracy, report = evaluate_model(model, test_loader, 'cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Accuracy: {accuracy:.4f}')\n",
        "print(report)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMPQzBR9yrTrMY84JKdM2WR",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
